https://leetcode.com/problems/network-delay-time/

class Solution {
public:
    const int N = 1e5+10;
    const int INF = 1e9+10;
    
    
    int dijkstra(int source,int n,vector<pair<int,int>> g[])
    {
        vector<int> dis(N,INF);
        vector<int> vis(N,0);
        
        set<pair<int,int>> st;
        st.insert({0,source});
        dis[source]=0;
        
        while(st.size()>0)
        {
            auto node = *st.begin();
            st.erase(st.begin());
            int v_dist = node.first;
            int v = node.second;
            if(vis[v])
                continue;
            vis[v]=1;
            for(auto child : g[v])
            {
                int child_v = child.first;
                int wt = child.second;
                
                if(dis[v]+wt<dis[child_v])
                {
                    dis[child_v]=dis[v]+wt;
                    st.insert({dis[child_v],child_v});
                }
                
            }
            
        }
        int ans=0;
        for(int i=1;i<=n;i++)
        {
            ans=max(ans, dis[i]);
            if(ans==INF)
                return -1;
        }
        return ans;
    }
    
    int networkDelayTime(vector<vector<int>>& times, int n, int k) {
        
        vector<pair<int,int>> g[N];
        for(auto vec : times)
        {
            g[vec[0]].push_back({vec[1],vec[2]});
        }
        return dijkstra(k,n,g);
        
    }
};
